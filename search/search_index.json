{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>SQL-focused Python ORM</p> <p>Sqlorm intends to provide a solution where SQL stays front and center and where the behavior of the ORM is what you expect and no more. SQL is seamlessly integrated through functions and model methods using Python doc strings.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install sqlorm-py\n</code></pre>"},{"location":"#getting-started","title":"Getting started","text":"<p>Create an <code>Engine</code> that will manage database connections for you:</p> <pre><code>from sqlorm import Engine\n\nengine = Engine.from_uri(\"sqlite://:memory:\")\n</code></pre> <p>Use the engine as a context to connect to the database. A transaction object is provided to execute statements. If no exception is raised in the context, the transaction will be committed, rollbacked otherwise.</p> <p>sqlorm's <code>Transaction</code> has a similar API than DBAPI's Connection but instead of using a cursor, methods return result sets that you can iterate over:</p> <pre><code>with engine as tx:\n    tx.execute(\"INSERT INTO tasks (title, done) VALUES ('task 1', false)\")\n    todos = tx.fetchall(\"SELECT * FROM tasks WHERE not done\")\n    task1 = tx.fetchone(\"SELECT * FROM tasks WHERE id = ?\", [1])\n    print(task1[\"title\"])\n</code></pre> <p>Each row above is the object returned by the underlying DBAPI driver.</p> <p>To fetch objects, you can pass a class using the <code>model</code> argument:</p> <pre><code>class Task:\n    pass\n\nwith engine as tx:\n    todos = tx.fetchall(\"SELECT * FROM tasks WHERE not done\", model=Task)\n    task1 = tx.fetchone(\"SELECT * FROM tasks WHERE id = ?\", [1], model=Task)\n    print(task1.title)\n</code></pre> <p>To facilitate managing sql statements, you can create \"sql functions\". These are functions which only have a doc string containing the SQL statement.</p> <pre><code>from sqlorm import sqlfunc\nimport datetime\n\n@sqlfunc(model=Task) # model is optional in which case it returns the rows directly\ndef fetch_todos():\n    \"SELECT * FROM tasks WHERE not done\"\n\n@sqlfunc.fetchone(model=Task) # specify the type of fetch to do\ndef fetch_most_recent_task():\n    \"SELECT * FROM tasks ORDER BY created_at DESC LIMIT 1\"\n\n@sqlfunc.fetchscalar\ndef count_tasks_created_between(start_date, end_date):\n    # Sql functions work similarly to f-strings, code in curly braces is evaluated and added to the sql\n    # code in python format placeholders %()s is evaluated and added as parameters.\n    # You can use function parameters\n    \"SELECT COUNT(*) FROM tasks WHERE created_at &gt;= %(start_date)s AND created_at &lt;= %(end_date)s\"\n\nwith engine:\n    todos = fetch_todos()\n    task = fetch_most_recent_task()\n    count = count_tasks_created_between(datetime.date.today() - datetime.timedelta(days=1), datetime.date.today())\n</code></pre> <p>Note: these functions must be executed in the context of a database session (or be bound to an engine)</p> <p>Finally, we can create model classes that can provide custom mapping information:</p> <pre><code>from sqlorm import Model, PrimaryKey, create_table\n\nclass Task(Model):\n    table = \"tasks\" # optional, use the class name by default\n\n    # these annotations are not needed but they provide auto completion and \n    # allow creating the table using create_table()\n    id: PrimaryKey[int]\n    title: str\n    done: bool\n\n    @classmethod\n    def find_all_todos(cls):\n        \"SELECT WHERE not done\" # SELECT FROM clause is automatically completed\n\n    def toggle(self):\n        # using RETURNING makes sure the object is updated with the new value\n        \"UPDATE {self.table} SET done = not done WHERE id = %(self.id)s RETURNING done\"\n\nwith engine as tx:\n    create_table(Task) # easily create a table from the model definition\n\n    # call your sql method and retreive a list of Task\n    todos = Task.find_all_todos()\n\n    # perform sql queries and get Task objects\n    # all the following operations are the same\n    todos = tx.fetchall(\"SELECT * FROM tasks WHERE not done\", model=Task)\n    todos = Task.query(\"SELECT * FROM tasks WHERE not done\")\n    todos = Task.query(Task.select_from().where(\"not done\"))\n    todos = Task.query(Task.select_from().where(Task.done == False))\n    todos = Task.find_all(Task.done == False)\n    todos = Task.find_all(\"not done\") # sql\n    todos = Task.find_all(done=False)\n\n    task = Task(title=\"second task\", done=True)\n    task.save() # executes the insert statement immediatly\n\n    # get by primary key\n    task = Task.get(1)\n    task.toggle()\n</code></pre>"},{"location":"#editor-support","title":"Editor support","text":"<p>VS Code syntax highlighting using extension</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>sqlorm is inspired by the many great ORMs that already exists in Python and other languages.</p> <p>Big shoutout to SQL Alchemy.</p> <p>On a side note, I had explored a similar approach in PHP in 2010 in my classql project.</p>"},{"location":"drivers/","title":"Drivers","text":""},{"location":"drivers/#drivers","title":"Drivers","text":"<p>sqlorm provides built-in support for the following databases:</p> Database DBAPI implementation URI scheme sqlorm overrides Required package SQLite sqlite3 sqlite:// Uses <code>sqlite3.Row</code> as the default row_factory and check_same_thread=False PostgreSQL psycopg3 postgresql:// No overrides psycopg[binary] MySQL mysql.connector mysql:// Uses <code>MySQLCursorDict</code> as default cursor class mysql-connector-python"},{"location":"drivers/#sqlite","title":"Sqlite","text":"<p>By default, Python's sqlite3 module does not allow a connection created in one thread to be re-used in another thread. This creates an issue with the way pooling works. Additionnaly, sqlorm's sessions being per-thread, there is a kind of guarantee that a connection object won't be used concurrently. For this reason, the default value of <code>check_same_thread</code> is set to false by default.</p> <p>Additional parameters are available when connecting:</p> <ul> <li>pragma: a dict of sqlite pragmas to set on connection</li> <li>ext: a list of extension modules to load on connection</li> <li>fine_tune: a boolean indicating to apply fine tuned pragmas for high concurrent workloads like web servers (explanations)</li> </ul>"},{"location":"drivers/#postgresql","title":"Postgresql","text":"<p>Some custom types are provided. You can also use a subclassed version of <code>SQL</code> with additional utils.</p> <pre><code>from sqlorm import Model, Text\nfrom sqlorm.drivers.postgresql import SQL, Array, JSON, JSONB\n\nclass MyModel(Model):\n    array_col = Column(type=Array(Text))\n    json_col = Column(type=JSON)\n    jsonb_col = Column(type=JSONB)\n\nwith engine:\n    rs = MyModel.find_all(MyModel.jsonb_col.op(\"@&gt;\", SQL.cast({\"key\": \"value\"}, JSONB))) # SELECT * FROM MyModel WHERE json_col @&gt; ('{\"key\": \"value\"}'::jsonb)\n    rs = MyModel.query(MyModel.select_from([MyModel.json_col.op(\"-&gt;&gt;\", \"property\")])) # SELECT json_col-&gt;&gt;property FROM MyModel\n</code></pre>"},{"location":"engine/","title":"The Engine","text":"<p>An engine is basically a connection manager for a DBAPI compatible module. It takes a dbapi module and a connection factory as argument.</p> <pre><code>from sqlorm import Engine\nimport sqlite3\n\nengine = Engine(sqlite3, lambda dbapi: dbapi.connect(\":memory:\"))\n</code></pre> <p>This can be simplified using <code>Engine.from_dbapi()</code> which takes the dbapi module as first argument and then any arguments for the <code>connect()</code> function.</p> <pre><code>engine = Engine.from_dbapi(sqlite3, \":memory:\")\n</code></pre> <p>Any DBAPI compatible database module can be used with sqlorm as long as it returns dict-compatible object for rows. Implementations that return tuples (the default in the case of sqlite3 for example) are not directly compatible. In this case, provide a custom connection factory (using <code>Engine.from_dbapi()</code>) that configure things nicely.</p> <p>Tip</p> <p>The module name can be provided as a string instead of a module reference. When provided as a string, sqlorm will first try to import the specified module under the <code>sqlorm.drivers</code> package. If it fails, it will import the specified module directly.</p> <p>In the case of sqlite, you can thus do <code>Engine.from_dbapi(\"sqlite\", \":memory:\")</code> to use sqlorm provided sqlite3 override.</p> <p>Finally, <code>Engine.from_uri()</code> provides an alternative way where an URI is used in the following way:</p> <ul> <li>the scheme specifies the dbapi module name</li> <li>the hostname+path part is passed as argument (optional)</li> <li>the query string (after ?) is parsed and passed as keyword arguments (optional)<ul> <li>True and False strings are parsed as boolean</li> <li>numbers are parsed as int</li> <li>keys can be repeated to create a list (eg: <code>foo=bar&amp;foo=buz</code> is parsed to <code>foo=[\"bar\", \"buz\"]</code>)</li> <li>keys with brackets are resolved as dict (eg: <code>foo[bar]=value</code> is parsed to <code>foo={\"bar\": \"value\"}</code>)</li> </ul> </li> </ul> <pre><code>engine = Engine.from_uri(\"sqlite://:memory:\") #\u00a0sqlite instead of sqlite3 to use sqlorm's sqlite override\nengine = Engine.from_uri(\"psycopg://?host=localhost&amp;port=5432\") # using the dbapi module name\n</code></pre> <p>Once initialized, an engine can be used as a context to start sessions.</p>"},{"location":"engine/#connecting","title":"Connecting","text":"<p>You shouldn't create connection manually when using sqlorm but use sessions.</p> <p>To create connections use <code>conn = engine.connect()</code>. To close a connection use <code>engine.disconnect(conn)</code>.</p>"},{"location":"engine/#connection-pool","title":"Connection pool","text":"<p>Connections are pooled and re-used by default. You can disabled this behavior by using <code>pool=False</code> in the engine constructor. <code>max_pool_conns</code> can also be used to define the maximum number of connections to start.</p> <p>Use <code>engine.disconnect_all()</code> to close all connections.</p>"},{"location":"engine/#engine-dispatcher","title":"Engine dispatcher","text":"<p>Multiple engines can be used at the same time. <code>EngineDispatcher</code> makes it easy to select engines based on matching tags.</p> <p>Register engines on the dispatcher using <code>dispatcher.register(engine, [\"tag1\", \"tag2\"])</code>.</p> <p>Select one engine using <code>dispatcher.tag_name</code>. If multiple engines matche a tag, one is randomly selected.</p> <pre><code>from sqlorm import EngineDispatcher\n\ndispatcher = EngineDispatcher()\ndispatcher.register(Engine.from_uri(\"postgresql://primary\"), default=True) #\u00a0there can be multiple default engines\ndispatcher.register(Engine.from_uri(\"postgresql://replica1\"), [\"readonly\"])\ndispatcher.register(Engine.from_uri(\"postgresql://replica2\"), [\"readonly\"])\n\nwith dispatcher:\n    # uses default engine (ie. primary)\n\nwith dispatcher.readonly:\n    # uses a randomly selected engines from the one matching the readonly tag (ie. replica1 or replica2)\n</code></pre> <p>The context behaves the same as a context from an Engine, ie. starting a transaction. To start a session instead, use <code>dispatcher.session(tag_name)</code>.</p> <p>By default, if no engines match the given tag, it will fallback on the default. This can be changed using the <code>fallback</code> argument of the <code>EngineDispatcher</code> constructor. Pass <code>False</code> to disable fallback or a tag name to fallback to a specific tag.</p> <p>Use <code>dispatcher.disconnect_all()</code> to close all connections across all engines.</p>"},{"location":"executing/","title":"Executing queries","text":"<p>Executing queries happens using transactions.</p> <p>Important</p> <p>When using sqlorm, you do not interact with cursors directly. Cursors will be created for each executed statements.</p>"},{"location":"executing/#executing-statements-with-no-results","title":"Executing statements with no results","text":"<p>Use the transaction's <code>execute(stmt, params)</code> method to execute a single non-returning statement. Parameters are optional. The first argument can be a list of statements.</p> <pre><code>with engine as tx:\n    tx.execute(\"CREATE TABLE tasks (id integer primary key, title text, done boolean)\")\n    tx.execute(\"INSERT INTO tasks (title, done) VALUES (?, ?)\", [\"task title\", True])\n</code></pre> <p>The parameters format (placeholders and values passed as argument to <code>execute()</code>) depends on the DBAPI driver.</p> <p>Use <code>ParametrizedStmt</code> to combine an sql statement and parameters:</p> <pre><code>from sqlorm import ParametrizedStmt\n\nwith engine as tx:\n    stmt = ParametrizedStmt(\"INSERT INTO tasks (title, done) VALUES (?, ?)\", [\"task title\", True])\n    tx.execute(stmt)\n</code></pre> <p><code>SQL</code> utilities to build sql statements can also be used:</p> <pre><code>from sqlorm import SQL\n\nwith engine as tx:\n    tx.execute(SQL.insert(\"tasks\", {\"title\": \"task title\", \"done\": True}))\n</code></pre>"},{"location":"executing/#fetching-from-the-database","title":"Fetching from the database","text":"<p>Use the transaction's <code>fetch(stmt, params)</code> method to fetch rows from the database. The cursor will be automatically closed when all rows have been fetched. It returns a <code>ResultSet</code> with a few methods to handle the cursor:</p> <ul> <li><code>fetch()</code> returns the next row in the cursor</li> <li><code>first()</code> returns the first row and closes the cursor</li> <li><code>all()</code> fetches all rows, closes the cursor and returns a list</li> <li><code>scalar()</code> fetches the first row and returns the value from the first column</li> <li><code>scalars()</code> fetches the value from the first column of each rows</li> <li><code>close()</code> closes the cursor manually</li> </ul> <p>The result set is iterable. There are a few shortcut methods on the transaction:</p> <ul> <li><code>fetchone()</code> is equivalent to <code>fetch().first()</code></li> <li>\u0300<code>fetchall()</code> is equivalent to <code>fetch().all()</code></li> <li><code>fetchscalar()</code> is equivalent to <code>fetch().scalar()</code></li> <li><code>fetchscalars()</code> is equivalent to <code>fetch().scalars()</code></li> </ul> <pre><code>with engine as tx:\n    task_row = tx.fetch(\"SELECT * FROM tasks WHERE id = ?\", [1]).first()\n    task_row = tx.fetchone(\"SELECT * FROM tasks WHERE id = ?\", [1]) # same as previous line\n\n    for row in tx.fetch(\"SELECT * FROM tasks\"):\n        print(row)\n\n    count = tx.fetchscalar(\"SELECT COUNT(*) FROM tasks\")\n    titles = tx.fetchscalars(\"SELECT title FROM tasks\")\n</code></pre> <p>The <code>loader</code> argument on <code>fetch()</code> can be used to process each rows:</p> <pre><code>with engine as tx:\n    titles = tx.fetchall(\"SELECT title FROM tasks\", loader=lambda r: r[\"title\"])\n</code></pre>"},{"location":"executing/#fetching-objects","title":"Fetching objects","text":"<p>Use the <code>model</code> argument of <code>fetch()</code> to fetch rows as objects.</p> <pre><code>class Task:\n    pass\n\nwith engine as tx:\n    tasks = tx.fetch(\"SELECT * FROM tasks\", model=Task)\n    task1 = tx.fetchone(\"SELECT * FROM tasks WHERE id = 1\", model=Task)\n</code></pre> <p>Note</p> <ul> <li>The process of populating objects with data from the database is called \"hydration\".</li> <li>When creating objects, <code>__init__()</code> will be bypassed as well as any custom <code>__setattr__</code>.</li> </ul> <p>Learn more about sqlorm hydration process in the mapper section</p> <p>You can update existing objects by passing an object instance to the <code>obj</code> argument. In this case, only the first row will be used to hydrate the object. The cursor is then closed.</p> <pre><code>with engine as tx:\n    task = Task()\n    tx.fetch(\"INSERT INTO tasks (title) VALUES ('task title') RETURNING *\", obj=task)\n    assert task.id\n    assert task.title == \"task title\"\n</code></pre> <p>Models and mappers can be used to customize how objects are mapped. <code>Mapper</code> instances can also be provided as models.</p>"},{"location":"executing/#composite-rows","title":"Composite rows","text":""},{"location":"executing/#what-are-composite-rows","title":"What are composite rows ?","text":"<p>It is common to use joins to fetch a row with its related rows at the same time. We then need to process the row to extract the composited rows. Because of the way joining works, a single composited rows can be represented as multiple returned rows. sqlorm handles this with a custom cursor iterator that will combine multiple rows and allow you to extract hierarchical data out of your results.</p> <p>To do so, sqlorm relies on column aliases. Column aliases will represent the path under which these composite rows will be nested. Use a double underscore (<code>__</code>) to separate each path segments.</p> <p>Example:</p> <pre><code>SELECT\n    posts.id,\n    posts.title,\n    posts.posted_at\n    comments.id AS comments__id\n    comments.author AS comments__author\n    comments.message AS comments__message\nFROM\n    posts\n    LEFT JOIN comments ON comments.post_id = posts.id\n</code></pre> <p>This query would return results like this:</p> id title posted_at comments__id comment__author comments__message 1 First post 2024-01-01 1 John First ! 1 First post 2024-01-01 2 Paul You make grammar mistakes... 2 Second post 2024-01-02 <p>And sqlorm will process them into the following structure:</p> <pre><code>[\n    {\n        \"id\": 1,\n        \"title\": \"First post\",\n        \"posted_at\": \"2024-01-01\",\n        \"comments\": [\n            {\n                \"id\": 1,\n                \"author\": \"John\",\n                \"message\": \"First !\"\n            },\n            {\n                \"id\": 2,\n                \"author\": \"Paul\",\n                \"message\": \"You make grammar mistakes...\"\n            }\n        ]\n    },\n    {\n        \"id\": 2,\n        \"title\": \"Second post\",\n        \"posted_at\": \"2024-01-02\"\n    }\n]\n</code></pre>"},{"location":"executing/#fetching-composite-rows","title":"Fetching composite rows","text":"<p>To fetch composite rows, use <code>fetchcomposite()</code>. It has a similar API to <code>fetch()</code>.</p> <pre><code>with engine as tx:\n    rows = tx.fetchcomposite(\"SELECT ... FROM posts LEFT JOIN comments ...\")\n</code></pre> <p>Using the <code>SQL</code> utilities makes it easier to build these kind of queries:</p> <pre><code>with engine as tx:\n    stmt = SQL.select(SQL.List([\n        SQL.Cols([\"id\", \"title\", \"posted_at\"], table=\"posts\"),\n        SQL.Cols([\"id\", \"author\", \"message\"], table=\"comments\", prefix=\"comments__\")\n    ])).from_(\"posts\").left_join(\"comments\").on(\"comments.post_id = posts.id\")\n\n    rows = tx.fetchcomposite(stmt)\n</code></pre>"},{"location":"executing/#fetching-composite-objects","title":"Fetching composite objects","text":"<p>The <code>model</code> argument can be used to return objects. The <code>nested</code> argument can be used to indicate what class to use for nested rows:</p> <pre><code>class Comment:\n    pass\n\nwith engine as tx:\n    stmt = \"...\"\n    tasks = tx.fetchcomposite(stmt, model=Task, nested={\"comments\": Comment})\n</code></pre> <p><code>fetchhydrated()</code> is an alias of <code>fetchcomposite()</code> where the model argument comes first:</p> <pre><code>with engine as tx:\n    tasks = tx.fetchhydrated(Task, stmt)\n</code></pre>"},{"location":"instrumentation/","title":"Instrumentation","text":"<p>SQLORM can be instrumented using OpenTelemetry.</p> <p>It supports automatic instrumentation or can be enabled manually:</p> <pre><code>from sqlorm.opentelemetry import SQLORMInstrumentor\n\nSQLORMInstrumentor().instrument(engine=engine)\n</code></pre> <p>You can optionally configure SQLORM instrumentation to enable sqlcommenter which enriches the query with contextual information.</p> <pre><code>SQLORMInstrumentor().instrument(enable_commenter=True, commenter_options={})\n</code></pre>"},{"location":"integrations/","title":"Integrations","text":""},{"location":"integrations/#flask","title":"Flask","text":"<p>See Flask-SQLORM.</p>"},{"location":"mapper/","title":"Mapping any class","text":"<p>Under the hood, models subclassing <code>Model</code> and other classes used as model are mapped using a <code>Mapper</code>. A mapper contains all the information needed to hydrate/dehydrate an object as well as utility methods to create SQL statements to fetch/save the data.</p>"},{"location":"mapper/#defining-mappers","title":"Defining mappers","text":"<p>Create a mapper and map some columns:</p> <pre><code>from sqlorm.mapper import Mapper, Column\n\nclass Task:\n    pass\n\nmapper = Mapper(Task, \"tasks\")\nmapper.map({\n    \"id\": Column(\"id\", primary_key=True),\n    \"title\": Column(\"title\"),\n    \"done\": Column(\"completed\") # in this example, the column is named \"completed\" but the attribute is named \"done\"\n})\n</code></pre> <p>Note</p> <p>The <code>Column</code> class used here is not the same as the one used in the models section. <code>Column</code> used in the model definitions is a subclass of the mapper's <code>Column</code> with support for property accessors and dirty attributes.</p> <p>By default, unknown columns will be accepted and set as attributes. This can be changed using <code>allow_unknown_columns=False</code> in mapper's constructor.</p> <p>Mappers can be created from any classes, in which case annotations will be used:</p> <pre><code>from sqlorm import PrimaryKey\n\nclass Task:\n    id: PrimaryKey[int]\n    title: str\n    done: bool # no column alias possible in this way (but possible when subclassing Model)\n\nmapper = Mapper.from_class(Task)\n</code></pre> <p>Tip</p> <p>Get the mapper associated to models using <code>Mapper.from_class(ModelClass)</code> or <code>ModelClass.__mapper__</code></p>"},{"location":"mapper/#hydrate-objects","title":"Hydrate objects","text":"<p>Use row data to populate an object.</p> <p><code>hydrate_new()</code> is used to create new object and hydrate it, <code>hydrate()</code> for existing objects.</p> <pre><code>data = {\"id\": 1, \"title\": \"task\", \"completed\": True}\n\ntask = mapper.hydrate_new(data)\n\ntask = Task()\nmapper.hydrate(task, data) # hydrate an existing object\n</code></pre> <p>Important</p> <p>When hydrating objects, <code>__init__()</code> will be bypassed as well as any custom <code>__setattr__</code>.</p> <p>By default, unmapped columns will be used and set as attributes. To prevent this, use <code>allow_unknown_columns=False</code> in the <code>Mapper</code> constructor or <code>with_unknown=False</code> in hydrate methods.</p> <p>Attributes that have been hydrated are available under the object's <code>__hydrated_attrs__</code> attribute.</p>"},{"location":"mapper/#dehydrating-objects","title":"Dehydrating objects","text":"<p>Extract data from an object and construct row data.</p> <pre><code>task = Task()\ntask.id = 1\ntask.title = \"task\"\ntask.done = True\ndata = mapper.dehydrate(task)\n</code></pre> <p>By default, if unknown columns are allowed, dehydration will also take into account all unknown attributes from <code>__hydrated_attrs__</code>. Use <code>dehydrate(..., with_unknown=False)</code> to prevent this.</p> <p>When creating update statements, use <code>with_primary_key=False</code> to not include the primary key as part of the dehydration process.</p>"},{"location":"mapper/#generating-sql-statements","title":"Generating SQL statements","text":"<p>A few useful methods to generate statementes:</p> <ul> <li><code>select_from()</code> to generate a select statement with the columns and table part already filled. The column list is generated using the mapping information and falls back to \"*\" when no columns are provided.</li> <li><code>select_by_pk()</code> to generate a select statement with a where condition on the primary key</li> <li><code>insert()</code> to generate the insert statement for an object</li> <li><code>update()</code> to generate the update statement</li> <li><code>delete()</code> to generate the delete statement</li> </ul> <pre><code>with engine as tx:\n    tasks = tx.fetchhydrated(mapper, mapper.select_from())\n    todos = tx.fetchhydrated(mapper, mapper.select_from().where(\"not done\"))\n\n    task1 = tx.fetchhydrated(mapper, mapper.select_from().where(\"id = 1\")).first()\n    task1 = tx.fetchhydrated(mapper, mapper.select_by_pk(1)).first()\n\n    task = Task()\n    tx.execute(mapper.insert(task))\n\n    task = Task()\n    task.id = 1\n    task.title = \"task\"\n    tx.execute(mapper.update(task))\n\n    tx.execute(mapper.delete(task))\n</code></pre> <p>The mapper column list <code>mapper.columns</code> is an <code>SQL.Cols</code> object which means it can be used to generate sql conditions:</p> <pre><code>with engine as tx:\n    todos = tx.fetchhydrated(mapper, mapper.select_from().where(mapper.columns.done==False))\n</code></pre>"},{"location":"models/","title":"Models","text":"<p>Any class can be used as a model. However, subclassing sqlorm's <code>Model</code> class provides a number of advantages:</p> <ul> <li>ActiveRecord style methods to quickly fetch / save the object</li> <li>Tracking of dirty attributes to only save attributes that have been modified</li> <li>Auto fetching lazy attributes and relationships when accessed</li> </ul> <p>Note</p> <p>When using classes that do not subclass <code>Model</code>, <code>Mapper.from_class()</code> is used to generate a mapping. See Mapping any class.</p>"},{"location":"models/#defining-models","title":"Defining models","text":"<p>Models are classes inheriting from <code>Model</code>. To define which table they represent, use the <code>table</code> class property.</p> <p>To define column mapping, define properties via annotations. The type used will be converted to an sql type. For more control over the mapping, you can use instantiate <code>Column()</code> objects:</p> <pre><code>from sqlorm import Model\n\nclass Task(Model):\n    table = \"tasks\"\n\n    id: int\n    title: str = Column(type=\"varchar(20)\") # set the column type (used in create_table())\n    done = Column(\"completed\", bool, default=False) # no annotation, column name is \"completed\" but property name will be \"done\"\n</code></pre> <p>Once columns are defined via annotations or <code>Column</code> properties, they are accessible as class and instance properties.</p> <p>As class properties, they can be used as a composable piece of sql:</p> <pre><code>stmt = SQL(\"SELECT * FROM tasks WHERE\", Task.done == False)\n</code></pre> <p>As instance properties, they can be get or set like any other property. Lazy loading and dirty flagging is performed accordingly.</p> <pre><code>task = Task()\ntask.title = \"title\"\n</code></pre> <p>Tip</p> <p>To create abstract models which are not meant to be mapped, make sure your class subclasses <code>abc.ABC</code></p> <pre><code>import abc\n\nclass MyBaseModel(Model, abc.ABC):\n    # ...\nclass MyModel(MyBaseModel):\n    # ...\n</code></pre>"},{"location":"models/#sql-methods-on-models","title":"SQL methods on models","text":"<p>Create SQL methods as you would SQL functions. Use <code>@classmethod</code> and <code>@staticmethod</code> decorator when needed.</p> <pre><code>class Task(Model):\n    @classmethod\n    def find_todos(cls):\n        \"SELECT * FROM tasks WHERE NOT done\"\n\n    def toggle(self):\n        \"UPDATE tasks SET done = NOT done WHERE id = %(self.id)s RETURNING *\"\n\nwith engine:\n    todos = Task.find_todos() # SELECT * FROM tasks WHERE NOT done\n\n    task = Task.get(1)\n    task.toggle() # UPDATE tasks SET done = NOT done WHERE id = 1 RETURNING *\n</code></pre> <p>By default, the following things happen:</p> <ul> <li>SELECT statements use <code>fetchhyddrated(Model, ...)</code></li> <li>INSERT and UPDATE statements use <code>execute()</code> unless <code>RETURNING</code> is used in the statement,   in which case it will update the object with the fetched value (using <code>fetchhydrated(Model, ..., obj=self)</code>)</li> <li>DELETE statements use <code>execute()</code></li> </ul> <p>You can change this default behavior using query decorators: <code>fetchall</code>, <code>fetchone</code>, <code>fetchscalar</code>, <code>fetchscalars</code>, <code>execute</code>, <code>update</code>.</p> <pre><code>from sqlorm import update\n\nclass Task(Model):\n    @update # update the object using the fetched row\n    def refresh_title(self):\n        \"SELECT title FROM tasks WHERE id = %(self.id)s\"\n\nwith engine:\n    task = Task(id=1)\n    task.refresh_title() # SELECT title FROM tasks WHERE id = 1\n    assert task.title\n</code></pre> <p>Because the SELECT FROM part of the query can be auto generated by sqlorm based on your model definition, you can start statements with SELECT WHERE directly.</p> <pre><code>class Task(Model):\n    @classmethod\n    def find_todos(cls):\n        \"SELECT WHERE NOT done\"\n</code></pre> <p>Similarly:</p> <ul> <li><code>INSERT INTO (col1) VALUES (%(value)s)</code> will be transformed to <code>INSERT INTO {table} (...</code></li> <li><code>UPDATE SET col = %(value)s</code> to <code>UPDATE {table} SET ...</code></li> <li><code>DELETE WHERE ...</code> to <code>DELETE FROM {table} WHERE ...</code></li> <li><code>WHERE SELF</code> to <code>WHERE {self.__mapper__.primary_key_condition(self)}</code></li> </ul> <p>You can also create methods using query decorators directly:</p> <pre><code>from sqlorm import Model, fetchall, update, SQL\n\nclass Task(Model):\n    @classmethod\n    @fetchall\n    def find_todos(cls):\n        return cls.select_from().where(done=False)\n\n    @update\n    def toggle(self):\n        return SQL.update(self.table, {\"done\": SQL(\"not done\")}).where(id=self.id).returning(\"*\")\n</code></pre> <p>Note</p> <p>Using <code>select_from()</code> also ensures that the column list, lazy and eager loading are respected.</p>"},{"location":"models/#querying-model-objects","title":"Querying model objects","text":"<p>Models can be used like any other classes with the <code>model</code> argument of the fetch api. However, <code>Model</code> also exposes easier to use ways to fetch data using without the need of explicitely passing a transaction. When called out of a transaction context, a non commited transaction will automatically be started. If bound to an engine, these class methods can also be called out of a session context.</p> <ul> <li><code>query()</code> executes the provided statement using <code>fetchhydrated()</code></li> <li><code>find_all()</code> constructs a select statement based on the provided arguments and executes using <code>query()</code></li> <li><code>find_one()</code> same as <code>find_all()</code> but only returns the first row</li> <li><code>get()</code> to find one row by primary key</li> </ul> <p>The two finder methods can take as argument a where condition (sql string) or keyword arguments representing attributes to filter by.</p> <pre><code>with engine:\n    todos = Task.query(\"SELECT * FROM tasks WHERE NOT done\")\n    todos = Task.find_all(\"NOT done\")\n    todos = Task.find_all(Task.done==False)\n    todos = Task.find_all(done=False)\n    task = Task.find_one(\"id=1\")\n    task = Task.get(1)\n</code></pre> <p>Tip</p> <p>You can also build select statement with auto populated column list and from clause using <code>Model.select_from()</code>.</p> <p>Mapped columns can easily be used as pieces of composable sql: accessing the class attribute representing the column returns an <code>SQL.Col</code> object that can be used with python operators to return sql conditions:</p> <pre><code>import datetime\n\nwith engine:\n    todos = Task.find_all(Task.done==False &amp; Task.created_at&lt;datetime.date.today())\n</code></pre>"},{"location":"models/#manipulating-model-objects","title":"Manipulating model objects","text":"<p>Manipulate model objects as you would with any python objects. The following methods help you execute DML statements:</p> <ul> <li><code>save()</code> executes <code>insert()</code> or <code>update()</code> depending on the fact that the object has a primary key or not</li> <li><code>insert()</code> executes an insert statement</li> <li><code>update()</code> executes an update statement</li> <li><code>delete()</code> deletes a delete statement</li> <li><code>refresh()</code> executes a select statement (same as <code>get()</code>) and updates the object attribute values</li> <li><code>create()</code> a class method to create and insert an object in one line</li> </ul> <p>These methods (apart from <code>create()</code>) return a boolean indicating if the operation was performed.</p> <p>Note</p> <p>DML (Data Manipulation Language) statements are the statement that modify data in the database (insert, update and delete mostly)</p> <p>The data used to insert or update will be limited to \"dirty\" attributes, which means attributes that have been modified since the last DML statement. Setting an attribute will automatically flag it as dirty.</p> <pre><code>from sqlorm import is_dirty\n\nwith engine:\n    task = Task.create(title=\"my task\") # INSERT INTO tasks (title) VALUES ('my task')\n\n    task = Task()\n    task.title = \"my task\"\n    task.save() # INSERT INTO tasks (title) VALUES ('my task')\n    # same as task.insert()\n\n    task = Task.get(1)\n    task.title = \"renamed task\"\n    assert is_dirty(task) == True\n    task.save() # UPDATE tasks SET title = 'renamed task' WHERE id = 1\n    # same as task.update()\n\n    task = Task.get(2)\n    task.delete() # DELETE FROM tasks WHERE id = 2\n\n    task = Task()\n    task.id = 1\n    task.refresh() # SELECT * FROM tasks WHERE id = 1\n</code></pre> <p>Tip</p> <p>You can also manually flag an attribute as dirty using <code>flag_dirty_attr(obj, attr)</code>. Dirty attributes are stored in the object's <code>__dirty__</code> attribute.</p> <p>If you do not wish to use dirty tracking, you can disable it in the model definition:</p> <pre><code>class MyBaseModel(Model, abc.ABC):\n    class Meta:\n        insert_update_dirty_only = False\n</code></pre> <p>Tip</p> <p>Which engine is used when manipulating models entirely depends on the current session context. Additionnally, sqlorm do not track objects globally. This means objects can be serialized easily and re-used in other sessions without any concept of \"attaching them\" etc...</p> <p>As a result, you can easily move objects from one engine to another:</p> <pre><code>with engine1:\n    task = Task.get(1) # SELECT * FROM tasks WHERE id=1\nwith engine2:\n    task.insert() # INSERT INTO tasks (id, ...) VALUES (1, ...)\n</code></pre>"},{"location":"models/#handling-unknown-columns","title":"Handling unknown columns","text":"<p>By default, unknown columns (ones which are not mapped), will be set as attributes on the object. Dirty attributes which are not mapped will also be saved in DML statements.</p> <p>You can thus create models with no mapped columns. However, models require a primary key to function properly. One will be automatically added when none are defined (named \"id\").</p> <p>When no columns are mapped, <code>SELECT *</code> is used.</p> <pre><code>class Task(Model):\n    table = \"tasks\"\n\nwith engine:\n    task = Task.find_all(done=False) # SELECT * FROM tasks WHERE done = false\n    print(task.title) # works\n    task.title = \"renamed task\"\n    task.save() # UPDATE tasks SET title = 'renamed task' WHERE id = 1\n</code></pre> <p>Tip</p> <p><code>ModelClass.c</code> is a shorthand to access the mapper columns (<code>ModelClass.__mapper__.columns</code>). When unknown columns are allowed, you can use any attributes to get a column object to build queries.</p> <pre><code>todos = Task.find_all(Task.c.done==False)\n</code></pre> <p>Warning</p> <p>You should not disable dirty tracking when allowing unknown columns otherwise setting attributes will not result in them being used in DML statements unless they are mapped. When dirty tracking is disabled and you are using unknown attributes, the only way sqlorm keeps track of them is through the <code>__hydrated_attrs__</code> attribute.</p> <p>You can disallow unknown columns</p> <pre><code>class MyBaseModel(Model, abc.ABC):\n    class Meta:\n        allow_unknown_columns = False\n</code></pre> <p>Or change the default primary key name:</p> <pre><code>class MyBaseModel(Model, abc.ABC):\n    class Meta:\n        auto_primary_key = \"uid\" # or False to disable auto creating primary key\n</code></pre>"},{"location":"models/#relationships","title":"Relationships","text":"<p>Define relationships on models using <code>Relationship(target_model, target_column, source_column)</code>:</p> <pre><code>from sqlorm import Relationship\n\nclass Post(Model):\n    comments = Relationship(\"Comment\", \"post_id\") # target model can be a string if not yet defined, default source column is the primary key\n\nclass Comment(Model):\n    post = Relationship(Post, \"id\", \"post_id\", single=True) # use single=True for many-to-one relationships\n\nwith engine:\n    post = Post.get(1)\n    for comment in post.comments: # SELECT executed now to load comments\n        print(comment.content)\n\n    comment = Comment.get(1)\n    print(comment.post.slug) # SELECT executed now to load post\n</code></pre> <p>Note</p> <p>There are no notion of backref like you may find in other ORMs. I prefer the explicit nature of declaring the relationship both ways</p> <p>The list of objects when not using single=True is not a normal python list. It can be iterated over and accessed through brackets. However, it only contains 2 methods to modify the list: append and remove. These methods will set the attribute on the related object. It will not save the object.</p> <pre><code>with engine:\n    post = Post.get(1)\n    comment = Comment(content=\"hello\")\n    post.comments.append(comment) # set comment.post_id\n    comment.save()\n</code></pre> <p>By default, relationships are always lazy loaded. Eager loading is possible by setting <code>lazy=False</code> or using <code>with_rels</code> in finder methods.</p> <pre><code>class Comment(Model):\n    post = Relationship(\"Post\", \"id\", \"post_id\", single=True, lazy=False) # add lazy=False\n\nwith engine:\n    c = Comment.get(1) # SELECT comments.*, posts.id as posts__id, posts.slug as posts__slug, ... FROM comments LEFT JOIN posts ON posts.id = comments.post_id\n    c.post.slug # no statement executed, already loaded\n\n    post = Post.get(1, with_rels=[\"comments\"]) # will load comments through the composite row mechanism\n    for comment in post.comments: # no statement executed, already loaded\n        # ...\n</code></pre> <p>Tip</p> <p>Use <code>with_rels=False</code> to prevent eager loading relationships</p> <p>Sometimes you want to query through relationships but not load the related objects. Use <code>with_joins</code> similarly as <code>with_rels</code> but it will only add the join clauses. You can also access attributes through the relationship object to get properly table aliased columns:</p> <pre><code>comments = Comment.find_all(Comment.post.slug==\"slug\", with_joins=[\"post\"]) # SELECT comments.* FROM comments LEFT JOIN posts ON posts.id = comments.post_id WHERE posts.slug == 'slug'\ncomments = Comment.query(Comment.select_from(with_joins=[Comment.post]).where(Comment.post.slug==\"slug\")) # alternative\n</code></pre> <p>Tip</p> <p>The join clause is customizable using <code>join_type</code> and <code>join_condition</code></p> <pre><code>class Post(Model):\n    comments = Relationship(\"Comment\", \"post_id\",\n        join_condition=\"{target_alias}.post_id = {source_alias}.id AND NOT {target_alias}.archived\") # an sql template with 2 special locals: target_alias and source_alias\n\nclass Comment(Model):\n    post = Relationship(Post, \"id\", \"post_id\", single=True, join_type=\"INNER JOIN\")\n</code></pre> <p>Note</p> <p>There are no support for many-to-many relationships for now</p> <p>Warning</p> <p>sqlorm does not handle deleting related objects when the parent is deleted. Use cascading rules in your table definitions.</p>"},{"location":"models/#binding-models-to-engines","title":"Binding models to engines","text":"<p>Unless bound to a specific engine, models will need a session context to execute statements. When bound to an engine, a non-commiting session is automatically created to execute statements.</p> <p>To bind models to an engine, create a new base model class using <code>Model.bind()</code>:</p> <pre><code>Model = Model.bind(engine)\n\nclass Task(Model):\n    pass\n\ntasks = Task.find_all() # works without a session context\n</code></pre> <p>You can also bind a model to an engine by simply setting its <code>__engine__</code> class attribute.</p> <p>Note</p> <p>While binding engine to models is possible, it is not the preferred way to use sqlorm</p>"},{"location":"models/#model-registry","title":"Model registry","text":"<p>When defining models using the <code>Model</code> class, the model classes are registered in a model registry available under <code>Model.__model_registry__</code>.</p> <p>Using <code>Model.bind()</code> will create a new registry only for the subclasses of this new base class.</p> <p>You can reference models in your sql methods:</p> <pre><code>class Post(Model):\n    def list_comments(self):\n        \"SELECT * FROM {Comment.table} WHERE {Comment.post_id} = %(self.id)\"\n\nclass Comment(Model):\n    pass\n</code></pre>"},{"location":"models/#eager-and-lazy-loading-columns","title":"Eager and lazy loading columns","text":"<p>Sometime you want to load additional data as part of the querying of objects and other times you want to delay loading additional data to when it's actually needed.</p> <p>Lazy and eager loading mechanism only apply when using <code>select_from()</code>, <code>find_all()</code>, <code>find_one()</code> and <code>get()</code>.</p> <pre><code>class Task(Model):\n    lazy_column = Column(lazy=True)\n\n    # create lazy groups: all columns of a group are loaded together when one is accessed\n    grouped_lazy_column1 = Column(lazy=\"group1\")\n    grouped_lazy_column2 = Column(lazy=\"group1\")\n\n\nwith engine:\n    task = Task.get(1)\n    # lazy columns are not loaded, they weren't included in the select statement\n    task.lazy_column # SELECT lazy_column FROM tasks WHERE id=1\n    task.grouped_lazy_column1 # SELECT grouped_lazy_column1, grouped_lazy_column2 FROM tasks WHERE id=1\n    task.grouped_lazy_column2 # no select, already loaded\n</code></pre> <p>You can eager load lazy fields using <code>with_lazy</code> in query methods:</p> <pre><code>with engine:\n    task = Task.get(1, with_lazy=True)\n    task = Task.get(1, with_lazy=[\"group1\"]) # only load some lazy items (column or group names)\n</code></pre>"},{"location":"models/#column-types","title":"Column types","text":"<p>Columns can have a type which defines the SQL type and serialization/deserialization functions.</p> <p>Note</p> <p>The goal is not to re-define sql types in python. Types are optional in your column definitions. sqlorm relies mainly on the underlying DBAPI driver to do the conversion. Drivers have custom methods to provide type mapping.</p> <p>Define types using <code>SQLType</code>:</p> <pre><code>from sqlorm import SQLType\nimport json\n\nJSON = SQLType(\"json\", json.loads, json.dumps)\n\nclass MyModel(Model):\n    my_json_column = Column(type=JSON)\n</code></pre> <p>The following types are already defines and importable from the <code>sqlorm</code> package:  <code>Integer</code>, <code>Decimal</code>, <code>Varchar</code>, <code>Text</code>, <code>Boolean</code>, <code>Date</code>, <code>Time</code>, <code>DateTime</code>, <code>JSON</code>, <code>Pickle</code>.</p> <p>Python types from annotations will automatically used one of these type when appropriate (see <code>sqlorm.types.PYTHON_TYPES_MAP</code>).</p>"},{"location":"schema/","title":"Managing the schema","text":""},{"location":"schema/#creating-tables-from-models","title":"Creating tables from models","text":"<p>Use <code>create_table()</code> to create the table associated to a model or mapper.</p> <pre><code>from sqlorm import create_table\n\nclass Task:\n    id: PrimaryKey[int]\n    title: str\n    done: bool\n\nwith engine:\n    create_table(Task)\n</code></pre> <p>Use <code>create_all()</code> to create all tables for models in a registry. If no registry is provided, <code>Model.__model_registry__</code> is used.</p> <pre><code>from sqlorm import create_all\n\nclass Task(Model):\n    id: PrimaryKey[int]\n    title: str\n    done: bool\n\nwith engine:\n    create_all()\n</code></pre> <p>You can check if a table exists first and prevent executing create table statements for existing tables using <code>check_missing=True</code>.</p> <p>Tip</p> <p>If you have bound your models to an engine, pass the model registry to <code>create_all()</code>:</p> <pre><code>Model = Model.bind(engine)\n\n# ... define models\n\nwith engine:\n    create_all(Model.__model_registry__)\n</code></pre>"},{"location":"schema/#migrations","title":"Migrations","text":"<p>sqlorm includes a simple one-way migration system. It will execute a list of sql or python files in order.</p> <p>Create a migrations folder with .sql or .py files prefixed with a version number (1 or more number) followed by an underscore and a name.</p> <pre><code>migrations/\n    000_init.sql\n    001_add_indexes.sql\n    002_seed_data.py\n</code></pre> <p>Use <code>migrate()</code> to execute these files in order. If no errors are raised during the run, the latest version is saved in a schema_version table in the database. It will be used as starting point for the next time you run <code>migrate()</code> (unless <code>use_schema_version=False</code> is used).</p> <pre><code>from sqlorm import migrate\n\nwith engine:\n    migrate()\n</code></pre> <p>Tip</p> <p>The transactions folder is resolved relative to the working directory. Provide an alternative path as first argument to <code>migrate()</code>.</p> <p>SQL files can contain multiple statements.</p> <p>In python files, use <code>ensure_transaction()</code> to create a transaction context:</p> <pre><code># 002_seed_data.py\nfrom sqlorm import ensure_transaction\n\nwith ensure_transaction() as tx:\n    tx.execute(\"...\")\n</code></pre>"},{"location":"schema/#initializing-the-database","title":"Initializing the database","text":"<p>Use <code>init_db()</code> to quickly initialize a database, either using <code>create_all(check_missing=True)</code> if no migrations exist or migrating the schema to the latest version.</p> <pre><code>from sqlorm import init_db\n\nwith engine:\n    init_db()\n</code></pre>"},{"location":"sessions-and-transactions/","title":"Sessions and transactions","text":"<p>Sessions are active connections to the database. A session can have multiple transactions as part of its lifecycle.</p> <p>When using the engine object as a context, a session and a transaction are created. The transaction will be commited on context exit if no error are raised, rollbacked otherwise.</p> <pre><code>with engine as tx:\n    tx.execute(\"INSERT INTO ...\")\n    # auto commited\n\nwith engine as tx:\n    tx.execute(\"INSERT INTO ...\")\n    raise Exception()\n    # rollback\n</code></pre> <p>The next section covers how to use transactions.</p> <p>Note</p> <p>You can create transactions inside transactions with no impact (only the top-most transaction will commit)</p> <pre><code>with engine as tx:\n    tx.execute(\"INSERT INTO ...\")\n    with engine as tx:\n        # ...\n</code></pre> <p>In most cases, using the engine as the context is the most straighforward method. However, in some circumstances you want to have an active session to be able to run select queries and eventually start transactions to perform modifications. This is a common use case in web applications.</p> <pre><code>with engine.session() as sess:\n    todos = Task.find_all(done=False)\n\n    with sess as tx:\n        Task.create(title=\"my task\")\n        # commit\n\n    todos = Task.find_all(done=False)\n    # rollback\n</code></pre> <p>Warning</p> <p>Session contexts are scoped to threads using thread locals. This means that using drivers which are not thread-safe (like sqlite) is not an issue as long as you are using the engine to start sessions. Doing <code>with engine.session()</code> and <code>with engine:</code> in different threads will start different sessions.</p> <p><code>transaction()</code> can be used to create a transaction in the currently available session context when the session context is not directly accessible:</p> <pre><code>from sqlorm import transaction\n\nwith engine.session():\n    with transaction() as tx:\n        Task.create(title=\"my task\")\n        # commit\n</code></pre> <p>To ensure that a transaction is available, use <code>ensure_transaction()</code>. This will ensure a session is available and create a virtual transaction (ie. which neither commit or rollback).</p> <pre><code>from sqlorm import ensure_transaction\n\ndef count_tasks():\n    with ensure_transaction() as tx:\n        return tx.fetchscalar(\"SELECT COUNT(*) FROM tasks\")\n\nwith engine:\n    c = count_tasks() # works\n    # commit\n\nwith engine.session():\n    c = count_tasks() # works\n    # rollback\n\ncount_tasks() #\u00a0raises MissingEngineError\n</code></pre> <p>Tip</p> <p><code>Session</code> can be created using raw DBAPI connection objects</p> <pre><code>from sqlorm import Session\nimport sqlite3\n\nconn = sqlite3.connect(\":memory:\")\n\nwith Session(conn) as sess:\n    with sess as tx:\n        # ...\n</code></pre>"},{"location":"signals/","title":"Signals","text":"<p>Signals allow you to listen and react to events emitted by sqlorm. The blinker lib is used to implement signals.</p>"},{"location":"signals/#engine","title":"Engine","text":"<p>The following signals exist on the <code>Engine</code> class. The sender is always the engine instance.</p> <ul> <li><code>connected</code>: receive <code>conn</code> (connection instance)</li> <li><code>pool_checkout</code>: connection checked out of the pool, receive <code>conn</code></li> <li><code>pool_checkin</code>: connection returned to the pool, receive <code>conn</code></li> <li><code>disconnected</code>: receive <code>conn</code> (connection instance)</li> </ul> <p>Example:</p> <pre><code>from sqlorm import Engine\n\n@Engine.connected.connect\ndef on_connected(engine, conn, from_pool):\n    # do something\n</code></pre>"},{"location":"signals/#session","title":"Session","text":"<p>The following signals exist on the <code>Session</code> class. The sender is always the session instance.</p> <ul> <li><code>before_commit</code></li> <li><code>after_commit</code></li> <li><code>before_rollback</code></li> <li><code>after_rollback</code></li> </ul> <p>Use <code>session.conn</code> to retreive the connection object (may be None if no connection have been established, use <code>session.connect()</code> in this case).</p> <p>Example:</p> <pre><code>from sqlorm import Session\n\n@Session.before_commit.connect\ndef on_before_commit(session):\n    # do something\n</code></pre>"},{"location":"signals/#transaction","title":"Transaction","text":"<p>The following signals exist on the <code>Transaction</code> class. The sender is always the transaction instance.</p> <ul> <li><code>before_execute</code>: receive <code>stmt</code>, <code>params</code> and <code>many</code> (to distinguish between execute and executemany)<ul> <li>when called from execute: returning a cursor will stop sqlorm execution and return the cursor directly</li> <li>when called from executemany: returning False will stop sqlorm execution</li> <li>in both case, returning a tuple <code>(stmt, params)</code> will override stmt and params</li> </ul> </li> <li><code>after_execute</code>: receive <code>cursor</code>, <code>stmt</code>, <code>params</code> and <code>many</code></li> <li><code>handle_error</code>: receive <code>cursor</code>, <code>stmt</code>, <code>params</code>, <code>many</code> and <code>exc</code>:<ul> <li>when handling for execute: return a cursor to prevent raising the exception</li> <li>when handling for executemany: return True to prevent raising</li> </ul> </li> </ul>"},{"location":"signals/#model","title":"Model","text":"<p>The following signals exist on the <code>Model</code> class. The sender is always the model class.</p> <ul> <li><code>before_query</code>: receive <code>stmt</code> and <code>params</code> args. can override them by returning a tuple <code>(stmt, params)</code></li> </ul> <p>The following signals receive <code>obj</code> kwargs containing the model instance. Returning <code>False</code> from any listener will cancel the operation. Returning a value will override the statement.</p> <ul> <li><code>before_refresh</code></li> <li><code>before_insert</code></li> <li><code>before_update</code></li> <li><code>before_delete</code></li> <li><code>before_save</code> (receive a <code>is_new</code> kwargs, can only cancel operations)</li> </ul> <p>The following signals are sent only if an operation is performed. They receive the <code>obj</code> kwargs containing the model instance.</p> <ul> <li><code>after_refresh</code></li> <li><code>after_insert</code></li> <li><code>after_update</code>: receive also <code>updated</code> a boolean indicating if an update stmt was actually performed</li> <li><code>after_save</code></li> <li><code>after_delete</code></li> </ul> <p>Examples:</p> <pre><code>from sqlorm import Model\n\n@Model.before_query.connect\ndef on_before_query(model_class, stmt, params):\n    # do something\n\n@Model.before_query.connect_via(MyModel)\ndef on_my_model_before_query(model_class, stmt, params):\n    # do something only on before_query of MyModel\n\n@Model.before_insert.connect\ndef on_before_insert(model_class, obj, stmt):\n    return False # cancel the insert\n\n@Model.before_insert.connect\ndef on_before_insert(model_class, obj, stmt):\n    return SQL.insert(model_class.table, {\"col\": \"value\"}) # return custom statement\n</code></pre>"},{"location":"sql-functions/","title":"SQL functions","text":"<p>SQL functions are python functions with only a docstring containing an SQL statement. To declare an SQL function, use the <code>sqlfunc</code> decorator. Unless bound to an engine using the <code>engine</code> argument, sql functions require a session context to be used.</p> <pre><code>from sqlorm import sqlfunc\n\n@sqlfunc\ndef fetch_todos():\n    \"SELECT * FROM tasks WHERE not done\"\n\nwith engine:\n    todos = fetch_todos()\n</code></pre> <p>The type of fetching being done can be controlled using <code>@sqlorm.fetchSTYLE()</code> instead:</p> <pre><code>from sqlorm import sqlfunc\n\n@sqlfunc.fetchscalar\ndef count_todos():\n    \"SELECT COUNT(*) FROM tasks WHERE not done\"\n\nwith engine:\n    nb_todos = count_todos()\n</code></pre> <p>The same arguments as fetch can be provided to the decorator.</p> <p>If you do not expect any return from your statement, use <code>@sqlfunc.execute</code>.</p> <p>The content of the docstring behaves similarly to f-strings:</p> <ul> <li>code in curly braces will be evaluated and be inserted in the final statement as is</li> <li>code in python format markers will be evaluated and inserted as parameters</li> </ul> <p>The function arguments are available in the evaluation context. The <code>SQL</code> utility as well as <code>datetime</code> and <code>uuid</code> are also available in the evaluation context.</p> <pre><code>from sqlorm import sqlfunc\n\n@sqlfunc.fetchscalar\ndef count_since(table, created_after, date_column=\"created_at\"):\n    \"SELECT COUNT(*) FROM {table} WHERE {date_column} &gt;= %(created_after)s\"\n\nwith engine:\n    tasks2024 = count_since(\"tasks\", \"2024-01-01\")\n</code></pre> <p>To get the sql statement of a function, use the <code>sql()</code> method on the function itself. It takes the same arguments as the decorated function. It returns an <code>SQLTemplate</code> object, itself a subclass of <code>SQL</code>.</p> <pre><code>print(count_since.sql(\"tasks\", \"2024-01-01\"))\n</code></pre> <p>Tip</p> <p>You can also create \"sql functions\" without using sql statements as docstrings using query decorators. Your function should then return a statement to execute (possibly parameterized using <code>ParametrizedStmt</code> or <code>SQL</code>).</p> <p>Available decorators are: <code>fetchall</code>, <code>fetchone</code>, <code>fetchscalar</code>, <code>fetchscalars</code>, <code>fetchcomposite</code>, <code>execute</code></p> <pre><code>from sqlorm import fetchall, execute\n\n@fetchall\ndef count_since(table, created_after, date_column=\"created_at\"):\n    return SQL.select(\"COUNT(*)\").from_(table).where(SQL(date_column) &gt;= SQL.Param(created_after)) # same as previous example\n\n@execute\ndef insert_task(title):\n    return SQL.insert(\"tasks\", {\"title\": title})\n\nwith engine:\n    tasks2024 = count_since(\"tasks\", \"2024-01-01\")\n    insert_task(\"my todo\")\n</code></pre> <p>Under the hood, <code>@sqlfunc</code> converts the docstring-only function to a function returning an <code>SQLTemplate</code> and wraps it in a query decorator</p>"},{"location":"sql-utilities/","title":"SQL utilities","text":"<p>sqlorm provides the <code>SQL</code> class to quickly and easily compose SQL statements.</p>"},{"location":"sql-utilities/#composable-pieces-of-parametrized-sql","title":"Composable pieces of parametrized SQL","text":"<p>An <code>SQL</code> object is just a piece of SQL that can be combined with other <code>SQL</code> objects to build a statement.</p> <pre><code>from sqlorm import SQL\n\n# combine pieces of sql\nq = SQL(\"SELECT * FROM table\")\nq = SQL(\"SELECT\", \"*\", \"FROM\", \"table\")\nq = SQL(\"SELECT *\") + SQL(\"FROM table\")\n</code></pre> <p>Use <code>SQL.Param</code> to embed parameters in your queries:</p> <pre><code>with engine as tx:\n    q = SQL(\"SELECT * FROM table WHERE id =\", SQL.Param(1))\n    task = tx.fetchone(q)\n</code></pre> <p>Note</p> <p>Parameters automatically use the apropriate paramstyle placeholder defined by the underlying DBAPI driver (default is \"qmark\").</p> <p>Use <code>.render()</code> to render an SQL object to a tuple containing the sql string and its parameters:</p> <pre><code>q = SQL(\"SELECT * FROM table WHERE id =\", SQL.Param(1))\n\nassert str(q) == \"SELECT * FROM table WHERE id = ?\"\n\nstmt, params = q.render()\nassert stmt == \"SELECT * FROM table WHERE id = ?\"\nassert params == [1]\n</code></pre> <p>Use Python operators to combine:</p> <pre><code>column = SQL(\"column_name\")\n\ns = column == SQL.Param(\"value\") # column_name = ?\ns = column &gt; SQL.Param(\"value\") # column_name &gt; ?\ns = column == SQL.Param(\"value\") &amp; column != SQL.Param(\"value2\") # (column_name = ? AND column_name != ?)\ns = column == SQL.Param(\"value\") | column == SQL.Param(\"value2\") # (column_name = ? OR column_name = ?)\ns = ~column # NOT column_name\ns = SQL.Param(\"value\").in_(column) # ? IN column\n</code></pre> <p>Or any custom sql operators:</p> <pre><code>s = column.op(\"MATCH\", SQL.Param(\"my text\"))\n</code></pre> <p>Calling methods on <code>SQL</code> objects can be used to build full SQL statements in pure python using method chaining.</p> <p><code>sql_object.keyword(*args)</code> is the same as <code>sql_object + SQL(\"KEYWORD\", *args)</code> (underscores in keyword are replaced by spaces and trimmed)</p> <pre><code>q = SQL().select(\"*\").from_(\"table\").where(column == SQL.Param(\"value\")).order_by(column)\n# is the same as\nq = SQL(\"SELECT\", \"*\", \"FROM\", \"table\", \"WHERE\", column == SQL.Param(\"value\"), \"ORDER BY\", column)\n</code></pre> <p>Useful shortcuts:</p> <ul> <li><code>SQL.select()</code> instead of <code>SQL().select()</code></li> <li><code>SQL.insert_into()</code> instead of <code>SQL().insert_into()</code></li> <li><code>SQL.update()</code> instead of <code>SQL().update()</code></li> <li><code>SQL.delete_from()</code> instead of <code>SQL().delete_from()</code></li> </ul>"},{"location":"sql-utilities/#query-builder","title":"Query builder","text":"<p>A query builder for SELECT statements, built on top of the <code>SQL</code> class, is provided.</p> <pre><code>from sqlorm import QueryBuilder\nquery = QueryBuilder().from_(\"table\").where(col=\"value\").where(SQL(\"col\") &gt;= 1)\n</code></pre> <p>It is aware of the different parts of the query and will treat them differently.</p> <ul> <li><code>builder.select()</code>, <code>.join()</code>, <code>.where()</code> will add expressions, all other parts will be replaced when called</li> <li>If <code>.select()</code> is not called, <code>SELECT *</code> is used</li> <li>Keyword arguments can be used with <code>.where()</code> to generate equal comparisons</li> </ul>"},{"location":"sql-utilities/#handling-list-of-sql-pieces","title":"Handling list of SQL pieces","text":"<p>Use <code>SQL.List</code> to manage lists of <code>SQL</code> objects. A few subclasses exists:</p> <ul> <li><code>SQL.List</code> renders a comma separated list of the rendered items</li> <li><code>SQL.Tuple</code> renders a parentheses enclosed comma separated list of the rendered items</li> <li><code>SQL.And</code> and <code>SQL.Or</code> renders a parentheses enclosed list separated by the boolean operator of the rendered items (this is used when combining using <code>&amp;</code> and <code>|</code>)</li> </ul> <pre><code>q = SQL.select(SQL.List([\"col1\", \"col2\"])).from_(\"table\") # SELECT col1, col2 FROM table\n\nq = SQL.insert_into(\"table\", SQL.Tuple([\"col1\", \"col2\"])).values(SQL.Tuple([SQL.Param(\"value1\"), SQL.Param(\"value2\")])) # INSERT INTO table (col1, col2) VALUES (?, ?)\n\nl = SQL.List()\nl.append(\"col1\") # SQL.List objects are subclasses of python's list\n</code></pre>"},{"location":"sql-utilities/#handling-columns","title":"Handling columns","text":"<p><code>SQL.Col</code> and <code>SQL.Cols</code> can be used to respectively represent a column and manage a list of columns:</p> <pre><code>q = SQL.select(SQL.Cols([\"col1\", \"col2\"], table=\"alias\")).from_(\"table AS alias\") # SELECT alias.col1, alias.col2 FROM table AS alias\n\nq = SQL.select(SQL.Cols([\"col1\", \"col2\"], prefix=\"prefix_\")).from_(\"table\") # SELECT col1 AS prefix_col1, col2 AS prefix_col2 FROM table\n\nq = SQL.select(SQL.Cols([SQL.Col(\"col1\", prefix=\"prefix_\"), SQL.Col(\"col2\", alias=\"colalias\")])).from_(\"table\") # SELECT col1 AS prefix_col1, col2 AS colalias FROM table\n\ncolumns = SQL.Cols([\"col1\", \"col2\", \"col3\"])\nprefixed_cols = columns.prefixed(\"prefix_\") # returns a new column list with all column prefixed\ncols_with_table = columns.aliased_table(\"table\") # returns a new column list with all column specifying the table name\ns = columns[\"col1\"] == SQL.Param(\"value\") # access individual columns\ns = columns.col2 == SQL.Param(\"value\")\n</code></pre>"},{"location":"sql-utilities/#easily-generate-insert-and-update-statements","title":"Easily generate insert and update statements","text":"<pre><code>with engine as tx:\n    tx.execute(SQL.insert(\"table\", {\"col1\": \"value1\"}))\n    tx.execute(SQL.update(\"table\", {\"col1\": \"value1\"}).where(\"id =\", SQL.Param(1)))\n</code></pre>"},{"location":"sql-utilities/#call-sql-functions","title":"Call SQL functions","text":"<p>Use <code>SQL.funcs.function_name()</code> where function_name is the SQL function name to render SQL function calls. All arguments are automatically wrapped in <code>SQL.Param</code> unless they are already an <code>SQL</code> object.</p> <pre><code>q = SQL(\"SELECT * FROM table WHERE col =\", SQL.funcs.lower(\"value\"))\nq = SQL(\"SELECT\", SQL.funcs.count(SQL(\"*\")), \"FROM table\")\n</code></pre>"},{"location":"sql-utilities/#templates","title":"Templates","text":"<p>Templates are the underlying mechanism of sql functions.</p> <ul> <li>code in curly braces will be evaluated and be inserted in the final statement as is</li> <li>code in python format markers will be evaluated and inserted as parameters</li> </ul> <pre><code>from sqlorm import SQLTemplate\n\ntpl = SQLTemplate(\"SELECT * FROM {table} WHERE created_at &gt;= %(created_at)s\")\nstmt, params = tpl.render({\"table\": \"my_table\", \"created_at\": \"2024-01-01\"})\n</code></pre>"}]}